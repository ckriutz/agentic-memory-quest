AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_DEPLOYMENT=
AZURE_OPENAI_API_VERSION=2024-10-01-preview
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small
QDRANT_HOST=
QDRANT_PORT=6333

GROK_DEPLOYMENT_NAME=grok-4-fast-non-reasoning
GPT4_DEPLOYMENT_NAME=gpt-4.1-mini
DEEPSEEK_DEPLOYMENT_NAME=DeepSeek-V3.2

# This is for the Hindsight Endpoint
HINDSIGHT_URL=http://localhost:8000

# Microsoft Foundry Configuration
AZURE_FOUNDRY_ENDPOINT=
# Required for agent-reference calls (Foundry portal agent name)
AZURE_FOUNDRY_AGENT_NAME=foundry-resort0-agent
AZURE_OPENAI_API_VERSION=2024-10-01-preview

# Deprecated / unused by the current integration (kept for compatibility)
AZURE_FOUNDRY_MODEL_DEPLOYMENT=gpt-5-mini

# Required: the agent name as defined in the Foundry portal
AZURE_FOUNDRY_AGENT_NAME=

# These items are for the Cognee configuration.
LLM_PROVIDER=openai
LLM_MODEL=azure/gpt-4.1
LLM_ENDPOINT=https://<your-resource>.openai.azure.com/openai/deployments/gpt-4.1
LLM_API_KEY=az-...
LLM_API_VERSION=2024-12-01-preview
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=azure/text-embedding-3-small
EMBEDDING_ENDPOINT=https://<your-resource>.openai.azure.com/openai/deployments/text-embedding-3-small
EMBEDDING_API_KEY=az-...
EMBEDDING_API_VERSION=2024-10-01-preview
EMBEDDING_DIMENSIONS=1536
VECTOR_DB_PROVIDER=qdrant
VECTOR_DB_URL=http://localhost:6333
VECTOR_DATASET_DATABASE_HANDLER=qdrant
# WARNING: DEBUG level logs API keys in plain text. Use WARNING or INFO in production.
LOG_LEVEL=WARNING

# Cognee relational DB storage — must be a writable path inside the container.
# Without this, Cognee defaults to writing SQLite inside its pip-installed
# package directory, which may not exist or be writable.
DB_PATH=/tmp/cognee_data/databases
DB_NAME=cognee_db

# ===========================================================================
# HOT/COLD Memory Layer — Azure AI Search + Event Hubs
# ===========================================================================

# Core feature flags
MEMORY_ENABLED=true
HOT_RETRIEVAL_ENABLED=true
COLD_INGEST_ENABLED=true
MEMORY_INDEX_NAME=memquest-dev-memory
MEMORY_K=8

# Azure AI Search
AZURE_SEARCH_ENDPOINT=
AZURE_SEARCH_API_KEY=
AZURE_SEARCH_SEMANTIC_RANKER_ENABLED=false
AZURE_SEARCH_SEMANTIC_CONFIG_NAME=default
AZURE_SEARCH_VECTOR_DIM=1536

# Event Hubs (cold path ingestion)
EVENT_HUBS_CONN_STR=
EVENT_HUBS_NAME=memory-events
EVENT_HUBS_CONSUMER_GROUP=$Default

# Embeddings
EMBEDDINGS_PROVIDER=azure_openai
AZURE_OPENAI_EMBED_MODEL=text-embedding-3-large

# PII Redaction
PII_REDACTION_ENABLED=true
PII_REDACTION_MODE=mask

# Memory Decider
MEMORY_DECIDER_LLM_ENABLED=false

# RRF
RRF_K=60

# Observability
OTEL_EXPORTER_OTLP_ENDPOINT=
LOG_LEVEL=info
